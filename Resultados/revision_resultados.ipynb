{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys        \n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections, functools, operator\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Parameters of system\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario 1: 187266979.79284772\n",
      "Escenario 2: 187066208.72272825\n",
      "Escenario 4: 187651217.07275575\n",
      "Escenario 5: 188163505.75720635\n",
      "Escenario 6: 183856704.7108145\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/moises/Desktop/Produccion-Tesis/')\n",
    "\n",
    "replicas = 1\n",
    "\n",
    "for experiment in [1, 2, 4, 5, 6]:            \n",
    "    file_name = f\"Resultados/Escenario {experiment}/\"\n",
    "    df = pd.read_pickle(file_name+\"objective_value.pkl\")\n",
    "    print(f\"Escenario {experiment}: {df['value'].sum()/replicas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "for experiment in range (1, 7):\n",
    "    # Recorrer cada experimento\n",
    "    if experiment in [1, 2,  3, 4, 5, 6]:\n",
    "        file_name = f\"Resultados/Escenario {experiment}/\"\n",
    "        df = pd.read_pickle(file_name+\"objective_value.pkl\").rename(columns={'value': 'utilidad'}).groupby(['r']).sum().reset_index()['utilidad']\n",
    "        df1 = pd.read_pickle(file_name+\"ingresos.pkl\").rename(columns={'value': 'ingresos'}).groupby(['r']).sum().reset_index()['ingresos']\n",
    "        df2 = pd.read_pickle(file_name+\"costo_inventario.pkl\").rename(columns={'value': 'costo_inventario'}).groupby(['r']).sum().reset_index()['costo_inventario']\n",
    "        df3 = pd.read_pickle(file_name+\"costo_corte.pkl\").rename(columns={'value': 'costo_corte'}).groupby(['r']).sum().reset_index()['costo_corte']\n",
    "        df4 = pd.read_pickle(file_name+\"costo_merma.pkl\").rename(columns={'value': 'costo_merma'}).groupby(['r']).sum().reset_index()['costo_merma']\n",
    "        df = pd.concat([df, df1, df2, df3, df4], axis=1)\n",
    "        df['Escenario'] = f\"Escenario {experiment}\"\n",
    "        df = df.reset_index().rename(columns={'index': 'r'})\n",
    "        df['r'] += 1\n",
    "\n",
    "        # Se agrega al DataFrame \n",
    "        final = pd.concat([final, df])\n",
    "        \n",
    "        fila = f\"Escenario {experiment} & \"\n",
    "        for metrica in ['utilidad', 'ingresos', 'costo_inventario', 'costo_corte', 'costo_merma']:\n",
    "            # Calcula la media y desviación estándar de la columna 'utilidad'\n",
    "            media = df[metrica].mean()\n",
    "            desviacion_estandar = df[metrica].std()\n",
    "\n",
    "            # Calcula el tamaño de la muestra\n",
    "            tamano_muestra = len(df)\n",
    "\n",
    "            # Define el nivel de confianza deseado (por ejemplo, 95%)\n",
    "            nivel_confianza = 0.95\n",
    "\n",
    "            # Calcula el valor crítico de la distribución t de Student\n",
    "            valor_critico = stats.t.ppf((1 + nivel_confianza) / 2, tamano_muestra - 1)\n",
    "\n",
    "            # Calcula el error estándar\n",
    "            error_estandar = desviacion_estandar / np.sqrt(tamano_muestra)\n",
    "\n",
    "            # Calcula el intervalo de confianza\n",
    "            intervalo_inferior = media - valor_critico * error_estandar\n",
    "            intervalo_superior = media + valor_critico * error_estandar\n",
    "\n",
    "            # Expresa el intervalo de confianza en potencia de 10e6 (potencia de 6)\n",
    "            media = \"{:.4f}\".format(media * 1e-6)\n",
    "            error = \"{:.4f}\".format(valor_critico * error_estandar * 1e-6)\n",
    "\n",
    "            # Imprime el intervalo de confianza expresado en potencia de 10e6 (potencia de 6)\n",
    "            cadena = f\"${media}$ $\\pm$ ${error}$ $\\\\times10^-6_$\".replace('-', '{'). replace('_', '}')\n",
    "            #print(f\"{metrica}:{cadena}\")\n",
    "\n",
    "            fila += f\"{cadena} & \"\n",
    "\n",
    "        fila =  fila[:-3]\n",
    "        if experiment != 6:\n",
    "            fila += \"\\\\\\\\ \\\\midrule \"\n",
    "        else:\n",
    "            fila += \"\\\\\\\\ \\\\bottomrule \"\n",
    "\n",
    "        print(fila)\n",
    "\n",
    "        \n",
    "#final\n",
    "final.to_excel(\"/Users/moises/Desktop/Codigo - Test significancia/ANOVA.xlsx\", sheet_name=\"ANOVA\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('random.json', 'r') as fp:\n",
    "    ERROR_DDA = json.load(fp)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    flattened_dict = {}\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            flattened_dict.update(flatten_dict(v, new_key, sep))\n",
    "        else:\n",
    "            flattened_dict[new_key] = v\n",
    "    return flattened_dict\n",
    "\n",
    "# Ejemplo de diccionario\n",
    "diccionario = ERROR_DDA\n",
    "\n",
    "# Aplicar la función flatten_dict para aplanar el diccionario\n",
    "flattened_dict = flatten_dict(diccionario)\n",
    "\n",
    "# Convertir el diccionario a un dataframe\n",
    "df = pd.DataFrame.from_dict(flattened_dict, orient='index', columns=['value']).to_excel('random.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
